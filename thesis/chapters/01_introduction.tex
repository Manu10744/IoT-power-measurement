% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Introduction}\label{chapter:introduction}
Despite being a relatively new concept, the Internet of Things (IoT) has become one of the most important and innovative technologies of the current century throughout the past years and it is continuously growing in importance in a multitude of fields such as traffic management, healthcare, agriculture and home automation. As IoT-enabled devices are usually equipped with a variety of sensors, they continuously produce data that comes in different shapes and sizes, which has to be delivered to connected devices using heterogeneous communication patterns. Consequently, this can result in an enormous energy consumption. As a matter of fact, the environment of IoT applications consisting of various devices and sensors often entirely depends on batteries as a power supply, which makes the operation of such applications potentially challenging due to the fact that the lifetime of batteries is usually quite limited. As a consequence, an efficient power management is a highly important task that must not be neglected because it is key to increase the expected lifetime of the utilized batteries and thus also the lifetime of the associated IoT applications. Though, usually this is no factor that is taken care of by the developers of an IoT application as they generally focus on implementing the logics rather than taking secondary aspects such as device failures or the amount of energy consumed into account.

Additionally, due to the rapidly growing importance of IoT, today's operation of IoT applications and corresponding devices introduces several other significant challenges and requirements including the need for high availability and scalability, a wide range of computing and storage resources, sufficient network capabilities and fault tolerance. To this end, innovative IoT platforms have been developed which are built on top of two modern concepts originating from the area of cloud computing, namely serverless computing and Function-as-a-Service (FaaS). While the former helps increase the productivity of the application developer team by completely taking care of the configuration and management of the deployment environment including the server and associated hardware on behalf of the user, the latter provides an event-driven architecture that facilitates the application development and decreases the complexity by breaking an application up into serverless functions, which are stateless, fine-grained parts of an application's business logic designed to run as ephemeral, standalone units, typically inside a containerized runtime environment. Usually, these environments are provisioned by cloud-native container orchestration tools such as Kubernetes or OpenShift. Today, application operators can already choose from a wide range of different FaaS platforms including both Open-Source solutions such as OpenWhisk or OpenFaaS and commercial products like Azure Functions or Google Cloud Functions. Regarding the implementation language of serverless functions, most of the current large FaaS providers support a wide range of popular programming languages such as NodeJS or Python. In addition to that, containerization tools like Docker can be used to package the function into a container image in order to deploy the serverless function to the respective FaaS platform. Subsequently, the function can be executed by simple HTTP requests as well as by more complex types of events like a scheduled job or an update in a database table. With regard to load balancing, most FaaS vendors offer autonomous scaling of serverless functions which results in more instances of a specific function getting deployed as soon as it is required by the incoming traffic. Equivalently, function instances are removed automatically as soon as there are more than needed to handle the current load.  In conclusion, developers and business operators benefit from being relieved the tremendous burden of having to setup and maintain the deployment environment themselves while the software can be operated using a highly flexible, decentralized infrastructure which is utilizable at a remarkable cost-efficiency due to the fact that serverless computing is typically charged based on a pay-as-you-use payment model. 

Though, current FaaS platforms are limited to homogeneous clusters of nodes as well as to homogeneous functions and the data access behavior of serverless functions during their scheduling is not taken into account, which are issues tackled by the recently proposed Function Delivery Network (FDN). Essentially, the FDN is a network of several distributed, heterogeneous serverless clusters incorporating a set of homogeneous nodes and a specific FaaS platform. For instance, there could be a high performance computing cluster of high-capacity virtual machines residing in the cloud that employs AWS Lambda as the corresponding FaaS platform and an edge computing cluster composed of various less powerful edge devices, which employs OpenFaaS as the underlying FaaS provider. The FDN supports heterogeneous clusters and heterogeneous functions requiring different amounts of computational and data resources by introducing the concept of Function-Delivery-as-a-Service (FDaaS), which takes care of delivering a function to the appropriate target platform based on its individual resource demands. As a result, this approach can lead to a higher application performance and a reduction of the overall energy consumption~\parencite{fdn}.

Presently, IoT-enabled edge devices like single-board computers can already be integrated into a serverless IoT platform, which allows for the deployment of serverless functions to the edge systems.~\parencite{fdn}. Though, the efficient management of the energy consumption of various edge systems operated in a cloud-native environment is a non-trivial task since the energy consumption of an electronic device depends on a variety of factors including computational effort, memory consumption and available hardware resources, which are typically quite different in that regard. Additionally, the scenario of multiple functions running simultaneously on the same edge device has to be taken into account as well. Furthermore, the carried out energy measurements have to be integratable into an already existing monitoring infrastructure, if available. Generally, both total energy consumption of an individual edge device and the energy consumption generated by the individual executions of serverless functions on the respective edge system are two important metrics that could help improve the utilization of the available battery power. Therefore, this thesis aims on providing an answer on the following questions:

\begin{enumerate}
  \item Given an existing monitoring infrastructure, how can an energy measurement for edge systems be implemented and integrated? In this regard, the Function Delivery Network which provides VMs, HPC servers and edge computers will be used in combination with Grafana as the data visualization platform.
  \item How can the energy consumption of serverless functions delivered to the edge systems be put in relation to the total power consumption of the respective device?
  \item To what extent can the energy consumption be influenced by utilizing different hardware resources or software?
\end{enumerate}

A Natural Language Processing application designed as a serverless function was chosen to serve as the basis for this work. The power measurements were carried out by an ESP32 powermeter which has been developed by the Chair of Computer Architecture \& Parallel Systems at the Technical University of Munich. By providing an appropriate interface, the edge computers were enabled to connect to the powermeter via WiFi in order to retrieve individual energy measurement data, which was subsequently pushed to the database and Grafana.

The rest of this thesis is structured as follows. Section 2 gives a brief overview of the various tools and technologies that have been employed for the purpose of this work such as Docker and Prometheus. In Section 3, a more detailed explanation of the Function Delivery Network and its individual components is given. Additionally, the structure and technical establishment of the experimental edge computing cluster as well as its integration into the FDN is thoroughly explained. Section 4 aims on introducing the individual approaches employed to provide an answer on the previously defined research questions. Section 5 describes the structure and location of the source code of the various software components that have been implemented for the purpose of this work. Finally, the individual results achieved with the previously presented approaches are evaluated in Section 6.